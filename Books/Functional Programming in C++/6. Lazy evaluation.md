- Executing code lazily and caching results can significantly improve the speed of your programs.

- It’s not often easy (and sometimes not even possible) to construct lazy variants of 2 algorithms you use in your programs, but if you manage to do it, you can make your programs much more responsive.

- A big class of algorithms has exponential complexity that can be optimized to be linear or quadratic just by caching intermediary results. 

- Levenshtein distance has many applications (in sound processing, DNA analysis, and spell checking, for instance) but can also find its place in regular programs.  When you need to notify the UI of changes in a data model, it’s useful to be able to minimize the number of operations the UI needs to perform.

- Although you should write the caching mechanisms for each problem separately, it’s sometimes useful to have functions such as make_memoized to benchmark the speed gain you could achieve by caching function results.

- Expression templates are a powerful mechanism for delaying computation. They’re often used in libraries that operate on matrices, and other places where you need to optimize expressions before handing them to the compiler.