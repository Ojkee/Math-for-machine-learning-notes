# AI-Papers

## List 
[The Annotated Transformer](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/The-Annotated-Transformer.pdf)
[The First Law of Complexodynamics](https://scottaaronson.blog/?p=762)
[The Unreasonable Effectiveness of Recurrent Neural Networks](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/The-Unreasonable-Effectiveness-of-Recurrent-Neural-Networks.pdf)
[Understanding LSTM Networks](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Understanding-LSTM-Networks.pdf)
[Recurrent Neural Network Regularization](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Recurrent-Neaural-Network-Regularization.pdf)
[Keeping Neural Networks Simple by Minimizing the Description Length of the Weights](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Keeping-Neural-Networks-Simple-by-Minimizing-the-Description-Length-of-the-Weights.pdf)
[Pointer Networks](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Pointer-Networks.pdf)
[ImageNet Classification with Deep Convolutional Networks](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/ImageNet-Classification-with-Deep-Convolutional-Networks.pdf)
[Order Matters Sequence To Sequence For Sets](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Order-Matters-Sequence-To-Sequence-For-Sets.pdf)
[GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/GPipe-Easy-Scaling-with-Micro-Batch-Pipeline-Parallelism)
[Deep Residual learning for Image Recognition](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Deep-Residual-learning-for-Image-Recognition.pdf)
[Multi-Scale Context Aggregation by Dilated Convolutions](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Multi-Scale-Context-Aggregation-by-Dilated-Convolutions.pdf)
[Neural Message Passing for Quantum Chemistry](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Neural-Message-Passing-for-Quantum-Chemistry.pdf)
[Attention Is All You Need](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Attention-Is-All-You-Need.pdf)
[Neural Machine Translation by Jointly Learning to Align and Translate](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate.pdf)
## Source
[link to blog](https://blog.wangxm.com/2024/06/ilyas-secret-machine-learning-paper-list/)

## Other
- [ ] [Mixing ADAM and SGD: a Combined Optimization Method](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Mixing-ADAM-and-SGD-a-Combined-Optimization-Method.pdf)
- [ ] [Generating-Sequences-With-Recurrent-Neural-Networks](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Generating-Sequences-With-Recurrent-Neural-Networks.pdf) 
- [ ] [Neural Machine Translation in Linear Time](https://github.com/Ojkee/Math-for-machine-learning-notes/blob/main/Papers/Neural-Machine-Translation-in-Linear-Time.pdf) 


